### 倒排索引

根据具体内容名或者属性来检索文章的结构，称作*倒排索引(inverted index)*， 在倒排索引中，key的集合叫做字典(Dictionary)， 一个key后面对应的记录集合叫做记录列表(Posting list).

![interved-index](https://github.com/checkking/notes/blob/master/imgs/inverted_idnex.png)

#### 如何创建倒排索引
1. 给每个文档编号， 作为唯一的标识，并且排好序, 然后遍历文档.
2. 解析当前文档中的每个关键字，生成<关键字, 文档ID, 关键字位置>这样的数据对。
3. 将关键字作为key插入哈希表。如果key已经在哈希表中，则在posting list后面追加节点，记录该文档ID(关键字的位置信息如果需要，也可以一并记录在节点中); 如果哈希表中没有这个key, 就直接插入key, 并创建posting list和对应节点。
4. 重复2-3步，处理完所有文档，完成倒排索引的创建.

![create-inverted-index](https://github.com/checkking/notes/blob/master/imgs/create_interved_index.png)

#### 检索同时包含关键字"hello", "world"两个key的文档
查询"hello", "world"两篇文档，以这两个词作为key检索倒排索引查找，得到两个posting list，我们需要同时包含两个关键字的posting list，就需要将这两个posting list的相同元素找出来。 如果posting list列表不是顺序的，查找操作的复杂度就是O(m\*n)，
但是，如果posting list的元素是有序的，则查找和用归并排序，复杂度就降为O(m+n)。

第一步, 使用指针p1和p2分别指向有序列表A和B的第一个元素。

第二步， 对比p1和p2所指元素是否相同:

* 两者id相同，说明是公共元素，直接将该节点加入归并结果。 然后p1++, p2++;

* p1的id < p2的id, p1++

* p1的id > p2的id, p2++

重复第2步，直到p1或p2移到链表结尾为止.


对于查找或的关系, 或者多个key查询的场景，也可以采用类似的方法。


说明： 这个只是一个简易的方法，对于数据量大的情况，或者真实的工业界场景，很显然是有性能问题的。

#### 倒排索引的加速
在倒排索引的检索过程中，两个posting list求交是最重要，最耗时的操作。有以下方法可以加速:

##### 跳表法加速倒排索引
假设posting list A 中的元素为 <1,2,3,4,5,6,7,8……，1000>，这 1000 个元素是按照从 1 到 1000 的顺序递增的。而 posting list B 中的元素，只有 <1,500,1000>3 个。那么按照我们之前的归并方法，在找到元素1以后，还需要再遍历 498 次链表，才能找到第二个相同元素 500。

![post1](https://github.com/checkking/notes/blob/master/imgs/pos_1.png)

我们可以通过将有序链表改成跳表，这样，在posting list A中，我们从第2个元素遍历到第500个元素，只需要 log(498) 次的量级，会比链表快得多。


![post2](https://github.com/checkking/notes/blob/master/imgs/pos2.png)

其实可以相互二分查找的，posting list A中，拿500在posting list B中二分查找，posting list B中，拿1000在posting list A中二分查找. 在实际的系统中，如果posting list可以都存储在内存中，并且变化不频繁的话，可以用*可变数组*来代替链表。 这样，对于两个posting list求交集，我们同样可以使用相互二分查找，进行归并，并且可以利用CPU的局部性提高性能。

##### 哈希表法加速倒排索引

假如posting list A的元素比posting list B的元素多很多，我们可以提前将posting list A存入哈希表中. 这样B中的每个元素查找A就是O(1)， 如果B有m个元素，就是O(m)。在真实场景中，提前把那些频繁需要求交的posting list用hash表存储，当然，为了这些posting list也能够有遍历能力，posting list本省也是要保留的。

##### 位图法加速倒排索引

posting list 用位图来存储, 但是有以下局限:
1. 位图法仅适用于只存储 ID 的简单的 posting list。如果 posting list 中需要存储复杂的对象，就不适合用位图来表示 posting list 了。
2. 位图法仅适用于 posting list 中元素稠密的场景。对于 posting list 中元素稀疏的场景，使用位图的运算和存储开销反而会比使用链表更大。
3. 位图法会占用大量的空间。尽管位图仅用 1 个 bit 就能表示元素是否存在，但每个 posting list 都需要表示完整的对象空间。如果 ID 范围是用 int32 类型的数组表示的，那一个位图的大小就约为 512M 字节。如果我们有 1 万个 key，每个 key 都存一个这样的位图，那就需要 5120G 的空间了。

##### 升级版位图：Roaring Bitmap

Roaring Bitmap将一个32位的整数分为两个部分，一部分是高16位，另一部分是低16位。对于高16位，Roaring Bitmap将它存储在一个有序数组中，有序数组的每个值都是一个“桶”; 对于低16位，将它存储在一个2^16的位图中，相应位置置为1。 这样每个通都会对应一个2^16的位图, 也就是8K。

![roaring-map](https://github.com/checkking/notes/blob/master/imgs/roaring_map.png)

要判断一个元素是否在Roaring Bitmap中，需要有两步，先在用高16位在有序数组中通过二分查找法,找到对应的桶， 然后用低16位在桶对应的bitmap找到对应的位置.第一步查找由于是数组二分查找，因此时间代价是 O（log n）；第二步是位图查找，因此时间代价是 O(1)。 其实，bitmap在数据很小的时候，可以退化成有序数组，比如元素小于4096，我们可以用有序数组来代替bitmap节省存储空间。


![roaring-map2](https://github.com/checkking/notes/blob/master/imgs/roaring_map2.png)

#### 联合查询进行加速
在日常的检索中，我们往往会面临更复杂的联合查询需求。这个时候，又该如何加速呢？

##### 调整次序法

假设，这里有 A、B、C 三个集合，集合中的元素个数分别为 2、20、40，而且 A 包含在 B 内，B 包含在 C 内。如果两个集合分别有 m 个元素和 n 个元素，那使用普通的遍历归并合并它们的时间代价为 O(m+n)。
当求交集次序是 A∩（B∩C）时，我们要先对 B 和 C 求交集，时间代价就是 20+40 = 60，得到的结果集是 B，然后 B 再和 A 求交集，时间代价是 2 + 20 = 22。因此，最终一共的时间代价就是 60 + 22 = 82。
那当求交集次序是（A∩B）∩C 时，我们要先对 A 和 B 求交集，时间代价是 2 + 20 = 22，得到的结果集是 A，然后 A 再和 C 求交集，时间代价是 2 + 40 = 42。因此，最终的时间代价就是 22 + 42 = 64。这比之前的代价要小得多。

![union](https://github.com/checkking/notes/blob/master/imgs/unio.png)

##### 快速多路归并法

调整次序法有一个前提，就是集合的大小要有一定的差异，这样的调整效果才会更明显。那如果我们要对多个 posting list 求交集，但是它们的长度差异并不大，这又该如何优化呢？

在对多个 posting list 求交集的过程中，我们可以利用跳表的性质，快速跳过多个元素，加快多路归并的效率。这种方法，我叫它"快速多路归并法"。在一些搜索引擎和广告引擎中，包括在 Elastic Search 这类框架里，就都使用了这样的技术。那具体是怎么做的呢？我们一起来看一下。

快速多路归并法的思路和实现都非常简单，就是将 n 个链表的当前元素看作一个有序循环数组list[n]。并且，对有序循环数组从小到大依次处理，当有序循环数组中的最小值等于最大值，也就是所有元素都相等时，就说明我们找到了公共元素。

第 1 步，将 4 个链表的当前第一个元素取出，让它们按照由小到大的顺序进行排序。然后，将链表也按照由小到大有序排列；

第 2 步，用一个变量 max 记录当前 4 个链表头中最大的一个元素的值；

第 3 步，从第一个链表开始，判断当前位置的值是否和 max 相等。如果等于 max，则说明此时所有链表的当前元素都相等，该元素为公共元素，那我们就将该元素取出，然后回到第一步；如果当前位置的值小于 max，则用跳表法快速调整到该链表中第一个大于等于 max 的元素位置；如果新位置元素的值大于 max，则更新 max 的值。

第 4 步，对下一个链表重复第 3 步，就这样依次处理每个链表（处理完第四个链表后循环回到第一个链表，用循环数组实现），直到链表全部遍历完。

##### 预先组合法

key1、key2 和 key3 分别的查询结果是 A、B、C 三个集合。如果我们经常会计算 A∩B∩C，那我们就可以将 key1+key2+key3 这个查询定义为一个新的组合 key，然后对应的 posting list 就是提前计算好的结果。之后，当我们要计算 A∩B∩C 时，直接去查询这个组合 key，取出对应的 posting list 就可以了。

##### 缓存法加速联合查询

缓存技术就是指将之前的联合查询结果保存下来。这样再出现同样的查询时，我们就不需要重复计算了，而是直接取出之前缓存的结果即可。这里，我们可以借助预先组合法的优化思路，为每一个联合查询定义一个新的 key，将结果作为这个 key 的 posting list 保存下来。缓存采用LRU。

#### 工业级倒排索引处理
我们为词典中的每个词编号，还会把每个词对应的编号字符串存入词典。在posting list中，除了记录文档ID, 还会记录该词在文档中出现的位置、词频等信息。整的倒排索引表结构如下图所示：

![inverted-index-final](https://github.com/checkking/notes/blob/master/imgs/inverted_index_final.png)

下面是生成工业级倒排索引的步骤：

首先，我们可以将大规模文档均匀划分为多个小的文档集合，并按照之前的方法，为每个小的文档集合在内存中生成倒排索引。

接下来，我们需要将内存中的倒排索引存入磁盘，生成一个临时倒排文件。我们先将内存中的文档列表按照关键词的字符串大小进行排序，然后从小到大，将关键词以及对应的文档列表作为一条记录写入临时倒排文件。这样一来，临时文件中的每条记录就都是有序的了。

而且，在临时文件中，我们并不需要存储关键词的编号。原因在于每个临时文件的编号都是局部的，并不是全局唯一的，不能作为最终的唯一编号，所以无需保存。


![tmp-index](https://github.com/checkking/notes/blob/master/imgs/tmp_index.png)

处理每一批的文档集合，最终磁盘中有多个临时文件。磁盘上的多个临时文件可以用多路归并技术进行合并成最终的完整倒排索引文件了。


![multi-merge](https://github.com/checkking/notes/blob/master/imgs/multi_merge.png)

将大任务分解为多个小任务，最终根据 key 来归并的思路，其实和分布式计算 Map Reduce 的思路是十分相似的。因此，这种将大规模文档拆分成多个小规模文档集合，再生成倒排文件的方案，可以非常方便地迁移到 Map Reduce 的框架上，在多台机器上同时运行，大幅度提升倒排文件的生成效率。

##### 倒排文件的检索
